---
title: "comp210-test"
aliases: 
tags: 
- assignment
- comp210
---

# 1

# 2

# 3


# 4
The term is used to indicate the reliability of a system. For example if a spam detector stopped 99.99% of spam emails it would be 5 nines secure.

# 5
Virtualisation of systems deployed on cloud platforms ensures that each of the systems are segregated from each other. This means that if one of the systems is compromised, it is very unlikely that this will lead to another service virtualised on the same hardware also being compromised as a result.

This means that a flaw in another organisation system that is virtualised on the same hardware as yours, cannot be exploited in a way that will affect your system.

# 6
It is important to have good security policies. These are high-level rules about the operations of an organisation. They provide a "roadmap" for the day-to-day operations of a company. They:

-   define the internal law of the company
-   are important for resolving legal disputes (provide accountability, and can protect the org and its employees)
-   ensure consistency regarding operations within the company
-   and provide evidence of quality control, internals audits, etc
-   they also help to answer questions about how the company should manage their data.

It is important that these policies are widely adopted and used the the members of the company. The company should create practices and procedures that make it as easy as possible for members of the company to put the policies into practice. The policies, practices, and procedures should be introduced to new staff members, and be widely available for all employees. They should not be overly complicated or strict as this will make it difficult for employees to use them. You should also regularly (e.g., once a month) check that they are being used, and if they are not, implmented changes to address the issues found

# 7
In machine learning a supervised approach uses labelled data for either classificaion or regression. You might use a regression to rank each packet according to how likely it is to be a threat. You could also simply use a classification algorithm such as a k-means classifiers to classify a packet as either a threat, a non-threat, or some other class such as outlier, or possible threat. An unsupervised approach uses unlabelled data, and attempts to find patterns, and group the data. The goal is to develop a better understanding of the data, rather than making predicions about future data. We could use k-means and DBCAN clustering to find groups of similar packets. We could also use t-SNE to visualise high dimension data.

# 8
One example of an ethical issue with machine learning is the use of machine learning algorithms for deepfakes. Deepfakes are essentially an advanced version of face swapping. They are very useful for things like adding deceased actors into films. However, there are many ethical issues with them. They can be utilised to produce fake videos of trusted leaders, such as politicians, they are designed to influence the publics opinion of them, or otherwise cause harm to society. DeepFaked videos are particularly damaging because although we have learned that text and images can be faked using applications like photoshop, the public generally places more trust in videos. This means that these videos are more likely to cause harm, as we are less wary of them. Furthermore, the mere existence of the ability to fake videos, means that the public can place less trust in videos of politicians etc, and means that these people may have to find other ways to ensure their content can be trusted. 

So, although machine learning deepfakes can be used for good purposes, they are also being used for bad purposes. When developing tools to produce deepfakes, the developers should consider the ethical implications of their software -  who might use their software, and for what purpose, and try to find out how to limit the harm that their software could cause.