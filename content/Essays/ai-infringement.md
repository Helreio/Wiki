---
title: Generative AI is Copyright Infringement In a Trench Coat
tags:
  - essay
  - seedling
  - ai
  - legal
  - copyright
date: 2023-11-04
draft: true
---
One ticket to the original, authorized, or in the alternative, properly licensed audiovisual work, please!

*A film roll clatters to the ground from underneath a suspiciously camera-shaped bulge in the figure's oversized trench coat.*

> [!info] I’m looking for discourse!
> Critique my points and make your own arguments. That’s what the comments section is for. 

Quick reiteration: **This site contains my own opinion in a personal capacity, and is not legal advice, nor is it representative of anyone else's opinion.**
- Also a reminder that I won’t permit inputting my work in whole or part into an LLM. 

I've seen a few news articles and opinion pieces recently that support training generative AI and LLMs on the broader internet as well as more traditional copyrighted works, without respect to the copyright holders for all of the above. For now, this will be less of a response to any one article and more of a collection of points of consideration that tie together common threads in public perception. I intend for this to become comprehensive.

My opinion here boils down to three main points:
- Training a generative AI model on copyrightable subject matter without authorization is copyright infringement (and the proprietors of the model should be responsible);
- Using a generative AI to generate something where the weights used to determine what the AI outputs were based on copyrightable subject matter trained on without authorization is copyright infringement (and the proprietors and users of the model should be jointly responsible); and
- Fair use is not a defense to either of the above infringements.
## Prologue: why these arguments are popping up
WIP
## The Legal Argument
Fair warning, this section is going to be the most law-heavy, and probably pretty tech-heavy too. Feel free to skip [[#The First Amendment and the "Right to Read"|-> straight to the policy debates.]] The field is notoriously paywalled, but I'll try to link to publicly available versions of my sources whenever possible.

Please don't criticize my sources in this section unless a case has been overruled or a statute has been repealed (ie, I **can't** rely on it). This is my interpretation of what's here (also again not legal advice or a professional opinion). Whether a case is binding on you personally doesn't weigh in on whether its holding is the nationally accepted view.

For all of the below analysis, assume that the hypothetical model in question has been trained on some work which has a US copyright registered with the original author.
### Training
Everything AI starts with a dataset. 

The core tenet of copyright is that the doctrine protects original expression, meaning you can't copyright facts. One common legal argument against training as infringement is that the AI extracts facts, not the author's creativity, from a work. But that position assumes that the AI is capable of first differentiating facts and art, and further separating them in a way analogous to the human mind's. First, let's talk about The Chinese Room.

[The Chinese Room](https://plato.stanford.edu/entries/chinese-room/) is a philosophical exercise authored by John Searle where the (in context, American) subject is locked in a room and receives symbols in Chinese slipped under the door. A computer program tells the subject what Chinese outputs to send back out under the door based on patterns and combinations of the input. The subject does not understand Chinese. Yet, it **appears** as if whoever is inside it has a firm understanding of the language to an observer of Searle's room.

Searle's exercise was at the time an extension of the Turing test designed to refute the theory of "Strong AI." At the time that theory was well-named, but today the AI it was talking about is not even considered AI by most. Strong AI was the theory that a computer could be programmed to  However, it can be easily applied to many other programming fields—notably compiler design—with the most pertinent here being natural language processing. To distinguish
- Note that some computer science sources like [IBM](https://www.ibm.com/topics/strong-ai) have taken to using Strong AI to denote AGI, which was only a sufficient, not necessary, quality of a philosophical "intelligent" intelligence.


- The idea and expression being the same may give rise to some claims of merger doctrine; that is, the idea merges with the expression, so it is not copyrightable. That would not be a correct reading of merger doctrine. [Ets-Hokin v. Skyy Spirits, Inc.](https://casetext.com/case/ets-hokin-v-skyy-spirits-inc) makes it clear that the doctrine is more about disregarding the types of works that are low-expressivity by default, and that this "merge" is just a nice name to remember the actual test by. Confusing name, easy doctrine.
### Generation

### Fair Use
#### Detour: actual harm caused by specific uses of AI models
My bet for a strong factor when courts start applying fair use tests to AI output is that the use in the instant case causes or does not cause harm. Here's a quick list of uses that probably do cause harm.

## The First Amendment and the "Right to Read"
WIP
## Putting your work "out there" on the internet
Artist's will, don't exploit
### Detour: plagiarism
There's also the problem of correctly sourcing information used in forming an opinion.

One proposed "solution" to AI use of copyrighted works is interestingly to attribute that those works were used in the first place.
## The enforcement problem
WIP

## Mini-arguments
A list of little statements that would cast doubt on the general legitimacy of the AI boom that I found compelling. Most are spread across the fediverse; others are blog posts/articles. 

- [Cartoonist Dorothy’s emotional story re: midjourney and exploitation against author intent](https://socel.net/@catandgirl/111766715711043428)
- [Misinformation worries](https://mas.to/@gminks/111768883732550499)